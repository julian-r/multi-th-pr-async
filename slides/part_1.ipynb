{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Multithreading, Multiprocessing und (AsyncIO) Co-Routines\n",
    "## und was macht da eigentlich das Betriebsystem?!?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Motivation\n",
    "\n",
    "- Betriebssysteme auf der TU\n",
    "- Long time ago: ein multi-cloud client\n",
    " - 1. Version mit Java und sehr sehr vielen Threads\n",
    " - 2. mit thread pools und Python ;)\n",
    "- Performance?\n",
    "  - Moores Law in Kernen(Transistoren) nicht in einzel CPU Power\n",
    "  - Skalierbarkeit (z.B. viele Netzwerkverbindungen)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Begriffe\n",
    "\n",
    "- Nebenläufigkeit / Concurrency\n",
    "- Paralellisierung / Parallelissm\n",
    "\n",
    "\n",
    "<img src=\"https://files.realpython.com/media/Screen_Shot_2018-10-17_at_3.18.44_PM.c02792872031.jpg\" >\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Was tut eine CPU beim Multitasking/processing?\n",
    "\n",
    "- Prozesse sollen nur auf den eigenen Speicher zugreifen koennen\n",
    "    - Pagetable/Speichervirtualisierung\n",
    "- Sicherheitsmodell (Ringe)\n",
    "    -Kernelspace hat mehr prvilegien als Userspace\n",
    "    - Bestimmte Instruktionen und Register(Parameter) koennen gesperrt werden (nur mehr im Kernelspace)\n",
    "- Interrupts\n",
    "   - Um den aktuellen Programmfluss zu unterbrechen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Threads, Prozesse, Userspace Threads/Coroutines\n",
    " - Sind Wege um Nebenläufigkeit zu verwenden\n",
    "     \n",
    " - Scheduler im Betriebssytem\n",
    "     - Threads \n",
    "     - Prozesse\n",
    " - Scheduler im Userspace:\n",
    "     - Coroutinen -> forsetzbare funktionen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Prozesse\n",
    " - Prozessattribute in Datenstruktur\n",
    "     - Umgebungsvariablen\n",
    "     - PID\n",
    "     - Prio etc.\n",
    " - Eigenen Virtuellen Speicherbereich\n",
    " - Eigener Stack\n",
    " ```c\n",
    " void bla() {\n",
    "     int a=1; // <-- stack\n",
    " ```\n",
    " - Eigener Heap\n",
    " ```c\n",
    "int* xyc = malloc(1024); // <-- heap\n",
    " ```\n",
    " - Wenn Datenaustausch notwendig, dann Aufwendiger (shared memory)\n",
    " - Betriebssystem wechselt zwischen Prozessen\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Kernel Threads\n",
    "- Pro Pozess -> N Threads\n",
    "- Leichtgewichtiger als Prozess\n",
    "- Geteilter Adressraum\n",
    "- Eigener Stack\n",
    "- Jeder Thread sein eigener Stack\n",
    "- Betriebssystem wechselt zwischen Prozessen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Wechseln zwischen Threads und Prozessen\n",
    " 1. Ein Interrupt oder Syscall(zB. lesen eines Files) wechselt in den Kernel\n",
    " 1. Der aktuelle CPU-State wird gespeichert\n",
    " 1. Der Kernel State wieder geladen\n",
    " 1. Ein neuer Prozess/Thread wird vom Scheduler ausgesucht\n",
    " 1. Der Kernel State wierd wieder gespeichert\n",
    " 1. Der CPU state wird wieder geladen\n",
    " 1. Wechsel in den Userspace\n",
    " \n",
    " <img src=\"https://www.ibm.com/support/knowledgecenter/en/SSGU8G_12.1.0/com.ibm.admin.doc/admin013.gif\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " # Context switching Performance\n",
    "- Benoetigt Zeit [3] (etwa 1-2 us)\n",
    " - Eine Python iteration braucht (~15ns) `1+1`\n",
    " - Wichtig? JA! (Aber es kommt drauf an...)\n",
    " - 100.000 Gleichzeitige Threads... 0.1-0.2s!\n",
    "- Unterschiedlicher Speicher\n",
    " - Verursacht cache misses\n",
    "- Worst case es wechselt der CPU Kern, dann kann gar kein Cache mehr verwendet werden.\n",
    "\n",
    "<img src=\"https://www.adamh.cz/public/img/context-switch-on-the-arm-cortex-m0/os_intro.png\">\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Co-Routines\n",
    " - Alternative: der User Prozess entscheided wann er unterbrochen werden kann -> in Python Generatoren\n",
    " ```py\n",
    " def abc_generator():\n",
    "    a = 1\n",
    "    yield \"b\"\n",
    "    print(a)\n",
    " ```\n",
    " - Funktionen die unterbrochen werden koennen\n",
    " - ... und dann wieder weiterlaufen koennen.\n",
    " - Vermutlich troztdem Cache misses (Vermutlich weniger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Was heisst das jetzt in Python?\n",
    " - `threading` -> Nebenlaeufkeit aber keine Paralellisierung (GIL)\n",
    " - `multiprocessing` -> Nebenlaeufigkeit und Paralellisierung\n",
    " - `co-routines` -> Userspace \"threads\" -> `asyncio`, `greenlet`, `twisted` etc.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# `threading`\n",
    "- wir teilen einen Speicher\n",
    "- Gut fuer einfache probleme mit *Nebenlaeufigkeit*\n",
    "- Schlecht wenn Multiprozessorsystem genutzt werden wollen wegen dem GIL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# `multiprocessing`\n",
    "- Protokoll with `threading` Modul\n",
    "- Wir haben einen Heap pro Prozess\n",
    "- GIL kein Thema\n",
    "- Inter-Prozess-Kommunikation (IPC) is langsam\n",
    "- Kein geteilter Speicher, alles muss pickelbar sein (Ausnamen gibt es)\n",
    "- kontext wechsel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# `asyncio`\n",
    "- Neu seit python 3.2\n",
    "- Ungewohnt\n",
    "- Micro-threading\n",
    "- Weniger Betriebssystemkontext wechsel\n",
    "- Fast kein locking!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## GIL\n",
    " - Eine VM-Instruktion gleichzeitig\n",
    " - Vorteil: teilweise atomar\n",
    " - Nachteil: Multiprozessorsysteme haben keinen Performancevorteil in einer Python Instanz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Code code code\n",
    "<img width='800' src=\"https://media1.giphy.com/media/OVtqvymKkkcTu/200.webp?cid=790b76115cf6921a74746f454566c350&rid=200.webp\" >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local 0.22460610099915357\n",
      "threading 1.4975726880002185\n",
      "mp 6.013863459998902\n"
     ]
    }
   ],
   "source": [
    "# How much is a lock?\n",
    "\n",
    "from timeit import timeit\n",
    "import threading\n",
    "import multiprocessing\n",
    "\n",
    "def local():\n",
    "    lock = True\n",
    "    for _ in range(100):\n",
    "        lock = False\n",
    "        lock = True\n",
    "\n",
    "def thread():\n",
    "    lock = threading.Lock()\n",
    "    for _ in range(100):\n",
    "        lock.acquire()\n",
    "        lock.release()\n",
    "\n",
    "def mp():\n",
    "    lock = multiprocessing.Lock()\n",
    "    for _ in range(100):\n",
    "        lock.acquire()\n",
    "        lock.release()\n",
    "\n",
    "number = 100_000\n",
    "print('local', timeit(local, number=number))\n",
    "print('threading', timeit(thread, number=number))\n",
    "print('mp', timeit(mp, number=number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local 0.007833464000214008\n",
      "threading 2.8562316289999217\n",
      "mp 34.35335968600066\n"
     ]
    }
   ],
   "source": [
    "from timeit import timeit\n",
    "import threading\n",
    "import multiprocessing\n",
    "\n",
    "def target():\n",
    "    yield None\n",
    "\n",
    "def local():\n",
    "    for _ in range(100):\n",
    "        target()\n",
    "\n",
    "def thread():\n",
    "    for _ in range(100):\n",
    "        threading.Thread(target=target).start()\n",
    "\n",
    "def mp():\n",
    "    for _ in range(100):\n",
    "        multiprocessing.Process(target=target).start()\n",
    "\n",
    "number = 100\n",
    "print('local', timeit(local, number=number))\n",
    "print('threading', timeit(thread, number=number))\n",
    "print('mp', timeit(mp, number=number))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# \"compute\" intense task\n",
    "\n",
    "from timeit import timeit\n",
    "from threading import Thread\n",
    "from multiprocessing import Process\n",
    "import asyncio\n",
    "\n",
    "COUNT = 1000000000\n",
    "\n",
    "\n",
    "def test(count):\n",
    "    print(\"test called\")\n",
    "    for i in range(count):\n",
    "        1 + 1\n",
    "\n",
    "\n",
    "def pure():\n",
    "    test(COUNT)\n",
    "\n",
    "\n",
    "def with_threading():\n",
    "    t1 = Thread(target=test, args=(COUNT // 2,))\n",
    "    t2 = Thread(target=test, args=(COUNT // 2,))\n",
    "    t1.start()\n",
    "    t2.start()\n",
    "    t1.join()\n",
    "    t2.join()\n",
    "\n",
    "\n",
    "def with_mp():\n",
    "    p1 = Process(target=test, args=(COUNT // 2,))\n",
    "    p2 = Process(target=test, args=(COUNT // 2,))\n",
    "    p1.start()\n",
    "    p2.start()\n",
    "    p1.join()\n",
    "    p2.join()\n",
    "\n",
    "\n",
    "async def test_wrapper(count):\n",
    "    return test(count)\n",
    "\n",
    "\n",
    "async def async_main():\n",
    "    asyncio.gather(test_wrapper(COUNT // 2), test_wrapper(COUNT // 2))\n",
    "\n",
    "\n",
    "def with_asyncio():\n",
    "    asyncio.run(async_main())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"threading\", timeit(with_threading, number=1))\n",
    "    print(\"mp\", timeit(with_mp, number=1))\n",
    "    print(\"pure\", timeit(pure, number=1))\n",
    "    print(\"aio\", timeit(with_asyncio, number=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Server/Client Beispiel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Und Jetzt?\n",
    "\n",
    " - `threading` ist super, weil einfach und man kennt das konzept\n",
    " - `multiprocessing` auch, aber wenn man mehr Berechnen wll\n",
    " - `asyncio` bzw greenlets sind super wenns um viel IO lastigen code geht\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " - [1]: http://axisofeval.blogspot.com/2010/11/numbers-everybody-should-know.html\n",
    " - [2]: https://eli.thegreenplace.net/2018/launching-linux-threads-and-processes-with-clone/\n",
    " - [3]: https://eli.thegreenplace.net/2018/measuring-context-switching-and-memory-overheads-for-linux-threads/\n",
    " - [4]: https://www.youtube.com/watch?v=KXuZi9aeGTw&feature=youtu.be\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3           0 BUILD_LIST               0\n",
      "              2 STORE_FAST               1 (a)\n",
      "\n",
      "  4           4 LOAD_FAST                1 (a)\n",
      "              6 LOAD_METHOD              0 (sort)\n",
      "              8 CALL_METHOD              0\n",
      "             10 POP_TOP\n",
      "             12 LOAD_CONST               0 (None)\n",
      "             14 RETURN_VALUE\n"
     ]
    }
   ],
   "source": [
    "import dis\n",
    "def a(x):\n",
    "    a = []\n",
    "    a.sort()\n",
    "\n",
    "dis.dis(a)\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
